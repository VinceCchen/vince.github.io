<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>
---
layout: post
title: "Fisher线性判别准则"
author: "Vince Cheng"
categories: learning
tags: [documentation,sample]
image: Fisher.jpg
---

# Fisher线性判别准则

在应用统计方法进行模式识别时，许多问题涉及到维数，在低维空间行得通的方法，往往在高维空间行不通，也称之为“维数灾难”。因此，降低维数常常成为解决实际问题的关键。将样本从高维的特征向量空间投影到一条直线上（实际上是把特征空间压缩到一维），这在数学上是容易办到的。

### 线性投影与Fisher准则函数
在 $\omega _{1}/\omega _{2}$ 两类问题中，假设有$n$个训练样本$x_{k}( k=1,2,\ldots ,n)$，其中$n_{1}$个样本来自$\omega _{1}$类型（构成训练样本的子集$X_{1}$），有$n_{2}$个样本来自$\omega _{2}$类型（构成训练样本的子集$X_{2}$），有$n=n_{1}+n_{2}$。
令$y_{k}=w^{T}x_{k}( k= 1,2,\ldots ,n)$，这里$y_{k}$是通过向量$x_{k}$变换$w$得到的标量。由子集$X_{1}$和$X_{2}$的样本映射后的两个子集为$Y_{1}$和$Y_{2}$。由于我们特别关注的是$w$的方向，所以可以令$\left| \left| w\right| \right|=1$,则$y_{k}$就是$x_{k}$在$w$方向上的投影。易见，使$Y_{1}$和$Y_{2}$最容易区分开的$w$方向正是分类超平面的法线方向，如下图所示。
![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1575567885426&di=0e9d806621cc2c622faddabc7e17dc09&imgtype=jpg&src=http%3A%2F%2Fimg2.imgtn.bdimg.com%2Fit%2Fu%3D2465420202%2C714058965%26fm%3D214%26gp%3D0.jpg)
图中样本在两个不同方向直线上的投影，可见图1中无法分开，而图2中给出的投影却可以分开。
下面讨论如何获得最佳$w$方向的解析式。
在d维特征空间中，各类样本均值向量为：
![](https://www.zhihu.com/equation?tex=%5Ctilde%7Bm_i%7D+%3D+%5Cfrac%7B1%7D%7Bn_i%7D%5Csum_%7By+%5Cin+D_i%7D+%7By%7D++%5C%5C)
我们希望这两类的样本均值尽可能地背离， 即![](https://www.zhihu.com/equation?tex=%5Ctilde%7BS_B%7D+%3D+%7C%5Ctilde%7Bm_1%7D+-+%5Ctilde%7Bm_2%7D%7C+%5E2)尽可能大。
另一方面，为了使得同一类别的投影尽可能地靠近，我们考虑类内样本的散度，![](https://www.zhihu.com/equation?tex=%5Ctilde%7Bs_i%5E2%7D+%3D+%5Csum_%7By+%5Cin+D_i%7D+%28y+-+%5Ctilde%7Bm_i%7D%29%5E2++%5C%5C)我们希望类内样本尽可能聚在同一区域，即![](https://www.zhihu.com/equation?tex=%5Ctilde%7BS_%7Bin%7D%7D+%3D+%5Ctilde%7Bs_%7B1%7D%5E2%7D++%2B+%5Ctilde%7Bs_%7B2%7D%5E2%7D+)尽可能地小。
综上，Fisher 判别分析的目标是:![](https://www.zhihu.com/equation?tex=%5Cmax_%7Bw%7D+J%28w%29+%3D+%5Cfrac%7B%7C%5Ctilde%7Bm_1%7D++-+%5Ctilde%7Bm_2%7D%7C%5E2%7D%7B%5Ctilde%7Bs_1%5E2%7D+%2B+%5Ctilde%7Bs_1%5E2%7D+%7D+%5C%5C)

参考：[知乎](https://zhuanlan.zhihu.com/p/61498028)

---







