---
layout: post
title: "Fisher线性判别准则"
author: "Vince Cheng"
categories: learning
tags: [documentation,sample]
image: Fisher.jpg
---

# Fisher线性判别准则

在应用统计方法进行模式识别时，许多问题涉及到维数，在低维空间行得通的方法，往往在高维空间行不通，也称之为“维数灾难”。因此，降低维数常常成为解决实际问题的关键。将样本从高维的特征向量空间投影到一条直线上（实际上是把特征空间压缩到一维），这在数学上是容易办到的。

### 线性投影与Fisher准则函数
在 $$\omega _{1}/\omega _{2}$$ 两类问题中，假设有$$n$$个训练样本$$x_{k}( k=1,2,\ldots ,n)$$，其中$$n_{1}$$个样本来自$$\omega _{1}$$类型（构成训练样本的子集$$X_{1}$$），有$$n_{2}$$个样本来自$$\omega _{2}$$类型（构成训练样本的子集$$X_{2}$$），有$$n=n_{1}+n_{2}$$。
令$$y_{k}=w^{T}x_{k}( k= 1,2,\ldots ,n)$$，这里$$y_{k}$$是通过向量$$x_{k}$$变换$$w$$得到的标量。由子集$$X_{1}$$和$$X_{2}$$的样本映射后的两个子集为$$Y_{1}$$和$$Y_{2}$$。由于我们特别关注的是$$w$$的方向，所以可以令$$\left| \left| w\right| \right|=1$$,则$$y_{k}$$就是$$x_{k}$$在$$w$$方向上的投影。易见，使$$Y_{1}$$和$$Y_{2}$$最容易区分开的$$w$$方向正是分类超平面的法线方向，如下图所示。
![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1575567885426&di=0e9d806621cc2c622faddabc7e17dc09&imgtype=jpg&src=http%3A%2F%2Fimg2.imgtn.bdimg.com%2Fit%2Fu%3D2465420202%2C714058965%26fm%3D214%26gp%3D0.jpg)
图中样本在两个不同方向直线上的投影，可见图1中无法分开，而图2中给出的投影却可以分开。
下面讨论如何获得最佳$$w$$方向的解析式。
在d维特征空间中，各类样本均值向量为：
![](https://www.zhihu.com/equation?tex=%5Ctilde%7Bm_i%7D+%3D+%5Cfrac%7B1%7D%7Bn_i%7D%5Csum_%7By+%5Cin+D_i%7D+%7By%7D++%5C%5C)
我们希望这两类的样本均值尽可能地背离， 即![](https://www.zhihu.com/equation?tex=%5Ctilde%7BS_B%7D+%3D+%7C%5Ctilde%7Bm_1%7D+-+%5Ctilde%7Bm_2%7D%7C+%5E2)尽可能大。
另一方面，为了使得同一类别的投影尽可能地靠近，我们考虑类内样本的散度，![](https://www.zhihu.com/equation?tex=%5Ctilde%7Bs_i%5E2%7D+%3D+%5Csum_%7By+%5Cin+D_i%7D+%28y+-+%5Ctilde%7Bm_i%7D%29%5E2++%5C%5C)我们希望类内样本尽可能聚在同一区域，即![](https://www.zhihu.com/equation?tex=%5Ctilde%7BS_%7Bin%7D%7D+%3D+%5Ctilde%7Bs_%7B1%7D%5E2%7D++%2B+%5Ctilde%7Bs_%7B2%7D%5E2%7D+)尽可能地小。
综上，Fisher 判别分析的目标是:![](https://www.zhihu.com/equation?tex=%5Cmax_%7Bw%7D+J%28w%29+%3D+%5Cfrac%7B%7C%5Ctilde%7Bm_1%7D++-+%5Ctilde%7Bm_2%7D%7C%5E2%7D%7B%5Ctilde%7Bs_1%5E2%7D+%2B+%5Ctilde%7Bs_1%5E2%7D+%7D+%5C%5C)

参考：[知乎](https://zhuanlan.zhihu.com/p/61498028)

# 进行试验
我选的是sonar数据集进行试验

### 导入数据
```python3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# 导入sonar.all-data数据集
sonar = pd.read_csv('sonar.all-data', header=None, sep=',')
sonar
```
数据格式如下：
![](https://img-blog.csdnimg.cn/20191207201905238.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1ZpbmNlX0NoZW5n,size_16,color_FFFFFF,t_70)

### 数据处理
```python3
# 数据处理
sonar1 = sonar.iloc[0:208,0:60]
sonar2 = np.mat(sonar1) # 创建矩阵
```

### 定义Fisher函数
```python3
def LDA(X1,X2,n):
        # 计算两类样本的类均值向量
    m1 = (np.mean(X1, axis=0))  # 按行计算的均值
    m2 = (np.mean(X2, axis=0))
    # 将行向量转换为列向量以便于计算
    m1 = m1.reshape(n,1)
    m2 = m2.reshape(n,1)
    
    # 计算类内离散度矩阵
    S1 = np.zeros((n,n))
    S2 = np.zeros((n,n))
    for i in range(0,97):
        S1 += (X1[i].reshape(n,1)-m1).dot((X1[i].reshape(n,1)-m1).T)
    for i in range(0,110):
        S2 += (X2[i].reshape(n,1)-m2).dot((X2[i].reshape(n,1)-m2).T)
            
    # 计算总类内离散矩阵S_w
    S_w = S1 + S2
    # 计算最优投影方向W
    W = np.linalg.inv(S_w).dot(m1-m2)   # linalg.inv()矩阵求逆
    
    return W

def Class(X,W):
    y = (W.T).dot(X)
    return y
```

### 进行试验
```python3
G1 = np.ones(98)
G2 = np.ones(110)
p1 = sonar2[0:97, 0:37]
p2 = sonar2[97:208, 0:37]
W = LDA(p1,p2,37)

for i in range(207):
    if i<= 96:
        test = p1[i]
        test = test.reshape(37,1)
        G1[i] = Class(test,W)
    else:
        test = p2[i-97]
        test = test.reshape(37,1)
        G2[i-97] = Class(test,W)

y1 = np.zeros(98)
y2 = np.zeros(110)+0.2
plt.figure(1)
plt.ylim((-0.5,0.5))
plt.xlim((-0.1,0.1))
plt.scatter(G1,y1,c='red',alpha=1,marker='.',label='G1')
plt.scatter(G2,y2,c='k',alpha=1,marker='.',label='G2')
plt.legend()
plt.show()

```

输出如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20191207202546152.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1ZpbmNlX0NoZW5n,size_16,color_FFFFFF,t_70)

我们发现其分类效果不是太好，我便参考[Mr_Lowbee](https://blog.csdn.net/Mr_Lowbee/article/details/86553946)的资料进行测试。

加了留一法。

代码如下：
```python3
def Fisher(X1,X2,n,c):
    # 计算两类样本的类均值向量
    m1 = (np.mean(X1, axis=0))  # 按行计算的均值
    m2 = (np.mean(X2, axis=0))
    # 将行向量转换为列向量以便于计算
    m1 = m1.reshape(n,1)
    m2 = m2.reshape(n,1)
    
    # 计算类内离散度矩阵
    S1 = np.zeros((n,n))
    S2 = np.zeros((n,n))
    if c == 0:
        for i in range(0,96):
            S1 += (X1[i].reshape(n,1)-m1).dot((X1[i].reshape(n,1)-m1).T)
        for i in range(0,111):
            S2 += (X2[i].reshape(n,1)-m2).dot((X2[i].reshape(n,1)-m2).T)
    if c == 1:
        for i in range(0,97):
            S1 += (X1[i].reshape(n,1)-m1).dot((X1[i].reshape(n,1)-m1).T)
        for i in range(0,110):
            S2 += (X2[i].reshape(n,1)-m2).dot((X2[i].reshape(n,1)-m2).T)
            
    # 计算总类内离散矩阵S_w
    S_w = S1 + S2
    # 计算最优投影方向W
    W = np.linalg.inv(S_w).dot(m1-m2)   # linalg.inv()矩阵求逆
    # 在投影后的一维空间求两类的均值
    m_1 = (W.T).dot(m1)
    m_2 = (W.T).dot(m2)
    
    # 计算分类阈值W0(为一个列向量)
    W0 = -0.5*(m_1 + m_2)
    
    return W,W0
    
def Classify(X,W,W0):
    y = (W.T).dot(X) + W0
    return y

# 观察图像发现当取维度n=37时，准确率与60一样，考虑计算量就选取n=37
G1 = np.ones(98)
G2 = np.ones(110)
p1 = sonar2[0:97, 0:37]
p2 = sonar2[97:208, 0:37]
count = 0
for i in range(207):
    if i <= 96:
        test = p1[i]
        test = test.reshape(37,1)
        train = np.delete(p1,i,axis=0)
        W,W0 = Fisher(train,p2,37,0)
        if (Classify(test,W,W0)) >= 0:
            count += 1
            G1[i] = Classify(test,W,W0)
    else:
        test = p2[i-97]
        test = test.reshape(37,1)
        train = np.delete(p2,i-97,axis=0)
        W,W0 = Fisher(p1,train,37,1)
        if (Classify(test,W,W0)) < 0:
            count += 1
            G2[i-97] = Classify(test,W,W0)

y1 = np.zeros(98)
y2 = np.zeros(110)+0.2
plt.figure(1)
plt.ylim((-0.5,0.5))
plt.xlim((-0.01,0.01))
plt.scatter(G1,y1,c='red',alpha=1,marker='.',label='G1')
plt.scatter(G2,y2,c='k',alpha=1,marker='.',label='G2')
plt.legend()
plt.show()

```

输出如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20191207203142529.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1ZpbmNlX0NoZW5n,size_16,color_FFFFFF,t_70)

效果明显提升。

---







